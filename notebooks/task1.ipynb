{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "+ You are going to read the code, prepare to answer the following questions:\n",
    "    + What is the purpose of the 3rd cell and 4th cell?\n",
    "    + Where does the variable **X_train/X_test** come from? How?\n",
    "+ Please reuse the code for new input \"bank2.csv\". Find what you need to change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Employ Pandas for data manipulation\n",
    "import numpy as np\n",
    "\n",
    "# 1. Import data\n",
    "bank_df = pd.read_csv('bank1.csv', sep=\";\") # default is \",\", which will fail\n",
    "\n",
    "bank_df_raw = bank_df.copy() # back up the original dataset for multiple tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = bank_df.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "bank_df_le = bank_df_raw.copy()\n",
    "\n",
    "for col in cat_cols:    \n",
    "    bank_df_le[col] = le.fit_transform(bank_df_le[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, \n",
    "              'jul': 7, 'aug': 8, 'sep':9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
    "\n",
    "bank_df_fix = bank_df_raw.copy()\n",
    "\n",
    "bank_df_le[\"month\"] = bank_df_fix[\"month\"].map(month_dict)\n",
    "bank_df_le.loc[bank_df_le['pdays']==-1,'pdays'] = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = bank_df_le.iloc[:,0:-1]\n",
    "y = bank_df_le.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) \n",
    "# set random_state=1 so that the results will be reproducible every time the code was run\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),('clf', LogisticRegression(random_state=1))])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "print('LG Train Accuracy: %.3f' % pipe_lr.score(X_train, y_train))\n",
    "print('LG Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))\n",
    "\n",
    "pipe_rf = Pipeline([('scl', StandardScaler()),('clf', RandomForestClassifier(random_state=1))])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "print('RF Train Accuracy: %.3f' % pipe_rf.score(X_train, y_train))\n",
    "print('RF Test Accuracy: %.3f' % pipe_rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid_rf = [{'clf__n_estimators': [20,40,80], 'clf__criterion': ['gini', 'entropy'], \n",
    "                  'clf__max_features': [3,10], 'clf__max_depth': [3, None], \n",
    "                  'clf__min_samples_split':[3,10], 'clf__min_samples_leaf':[3, 10],\n",
    "                  'clf__bootstrap': [True, False]}]\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf, param_grid=param_grid_rf, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "gs_rf_fit = gs_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Best score for RF: %.3f' % gs_rf_fit.best_score_)\n",
    "print('Best param for RF: %s' % gs_rf_fit.best_params_)\n",
    "\n",
    "gs_rf_best = gs_rf_fit.best_estimator_\n",
    "print('RF Train accuracy: %.3f' % gs_rf_best.score(X_train, y_train))\n",
    "print('RF Test accuracy: %.3f' % gs_rf_best.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=gs_rf_best, X=X_train, \n",
    "                                                        y=y_train, train_sizes = np.linspace(0.1,1,10),\n",
    "                                                        cv=10, n_jobs=-1)\n",
    "\n",
    "# Mean and Std across K-Folds, which result in mean and std for each subset of X_train with different sample size\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "print('train_scores_mean: ', train_scores_mean)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "print('train_scores_std: ', train_scores_std)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "print('test_scores_mean: ', test_scores_mean)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "print('test_scores_std: ', test_scores_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean+train_scores_std, \n",
    "                 train_scores_mean-train_scores_std, alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_scores_mean, color='green', linestyle='--', marker='s', \n",
    "         markersize=5, label='validation accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes, test_scores_mean+test_scores_std, \n",
    "                 test_scores_mean-test_scores_std, alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf_final = gs_rf_best\n",
    "clf_final.fit(X_train, y_train)\n",
    "y_pred = clf_final.predict(X_test)\n",
    "print('Test accuracy: %.3f' % clf_final.score(X_test, y_test))\n",
    "\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
